{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FB_Covid.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO6BKrQpRO+OwFZQpgTN0jR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "45bc699e94c24cc5b66302699d5e11d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7b11e708a669457780bb2daf6f0dac0d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_721f66da6423425082b0415eb825652b",
              "IPY_MODEL_572d195881844f8fa164f2a283b21fa8"
            ]
          }
        },
        "7b11e708a669457780bb2daf6f0dac0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "721f66da6423425082b0415eb825652b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_890ec187a75f4ee6b461063e3372fc54",
            "_dom_classes": [],
            "description": "Validation sanity check: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c77cc07e902c4818aa08544f3fb34554"
          }
        },
        "572d195881844f8fa164f2a283b21fa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a0125e1269264dfebeabc146010b8f0e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [00:00&lt;00:00,  2.33it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_90db964d2ba34afa8b1c480feee39f6f"
          }
        },
        "890ec187a75f4ee6b461063e3372fc54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c77cc07e902c4818aa08544f3fb34554": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a0125e1269264dfebeabc146010b8f0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "90db964d2ba34afa8b1c480feee39f6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanmayg/LS/blob/master/FB_Covid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeNU4Ode7l7k"
      },
      "source": [
        "#!pip install pytorch_lightning"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkJV1bUsOiuT"
      },
      "source": [
        "import logging\r\n",
        "import os\r\n",
        "from argparse import ArgumentParser\r\n",
        "from pathlib import Path\r\n",
        "from warnings import warn\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import pytorch_lightning as pl\r\n",
        "import torch\r\n",
        "import yaml\r\n",
        "import argparse\r\n",
        "\r\n",
        "argparser = argparse.ArgumentParser()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Omthm1q7rf0z",
        "outputId": "66328c68-4fbb-4682-81af-c7f9eb5ca3aa"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08Yh_wU8Pnrp"
      },
      "source": [
        "from transforms import (\r\n",
        "    Compose,\r\n",
        "    HistogramNormalize,\r\n",
        "    NanToInt,\r\n",
        "    RemapLabel,\r\n",
        "    TensorToRGB,\r\n",
        ")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zm1esry_P0WQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "982e5055-e735-4964-e470-9fe69bb4f7c3"
      },
      "source": [
        "from xray_datamodule import XrayDataModule"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Running in Test mode!!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6Lg0rrkP52x"
      },
      "source": [
        "from torchvision import transforms\r\n",
        "from sip_finetune import SipModule"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZY0iJaISFgY"
      },
      "source": [
        "#!python train_sip.py --pretrained_file mimic-chexpert_lr_0.01_bs_128_fd_128_qs_65536.pt"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJOTNLS-mawC"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_HfjWKGER58"
      },
      "source": [
        "argparser.add_argument(\"--pretrained_file\", help=\"Pretrained File\", default=\"mimic-chexpert_lr_0.01_bs_128_fd_128_qs_65536.pt\")\r\n",
        "argparser.add_argument(\"--im_size\", default=224, type=int)\r\n",
        "argparser.add_argument(\"--uncertain_label\", default=np.nan, type=float)\r\n",
        "argparser.add_argument(\"--nan_label\", default=np.nan, type=float)\r\n",
        "args = argparser.parse_args([\"--pretrained_file\", \"mimic-chexpert_lr_0.01_bs_128_fd_128_qs_65536.pt\"])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IU2p7YX7AjO6",
        "outputId": "b11de797-1bcc-49d7-fab1-4c6c85d8c479"
      },
      "source": [
        "args"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Namespace(im_size=224, nan_label=nan, pretrained_file='mimic-chexpert_lr_0.01_bs_128_fd_128_qs_65536.pt', uncertain_label=nan)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gr4ffHStjwJ"
      },
      "source": [
        "def build_args(arg_defaults=None):\r\n",
        "    pl.seed_everything(1234)\r\n",
        "    data_config = Path.cwd() / \"data.yaml\"\r\n",
        "    tmp = arg_defaults\r\n",
        "    arg_defaults = {\r\n",
        "        \"accelerator\": \"ddp\",\r\n",
        "        \"batch_size\": 32,\r\n",
        "        \"max_epochs\": 5,\r\n",
        "        \"gpus\": 1,\r\n",
        "        \"num_workers\": 10,\r\n",
        "        \"callbacks\": [],\r\n",
        "    }\r\n",
        "    if tmp is not None:\r\n",
        "        arg_defaults.update(tmp)\r\n",
        "\r\n",
        "    # ------------\r\n",
        "    # args\r\n",
        "    # ------------\r\n",
        "    parser = ArgumentParser()\r\n",
        "    parser.add_argument(\"--im_size\", default=224, type=int)\r\n",
        "    parser.add_argument(\"--uncertain_label\", default=np.nan, type=float)\r\n",
        "    parser.add_argument(\"--nan_label\", default=np.nan, type=float)\r\n",
        "    parser = pl.Trainer.add_argparse_args(parser)\r\n",
        "    parser = XrayDataModule.add_model_specific_args(parser)\r\n",
        "    parser = SipModule.add_model_specific_args(parser)\r\n",
        "    parser.set_defaults(**arg_defaults)\r\n",
        "    args = parser.parse_args()\r\n",
        "\r\n",
        "    if args.default_root_dir is None:\r\n",
        "        args.default_root_dir = Path.cwd()\r\n",
        "\r\n",
        "    if args.pretrained_file is None:\r\n",
        "        warn(\"Pretrained file not specified, training from scratch.\")\r\n",
        "    else:\r\n",
        "        logging.info(f\"Loading pretrained file from {args.pretrained_file}\")\r\n",
        "\r\n",
        "    if args.dataset_dir is None:\r\n",
        "        with open(data_config, \"r\") as f:\r\n",
        "            paths = yaml.load(f, Loader=yaml.SafeLoader)[\"paths\"]\r\n",
        "\r\n",
        "        if args.dataset_name == \"nih\":\r\n",
        "            args.dataset_dir = paths[\"nih\"]\r\n",
        "        if args.dataset_name == \"mimic\":\r\n",
        "            args.dataset_dir = paths[\"mimic\"]\r\n",
        "        elif args.dataset_name == \"chexpert\":\r\n",
        "            args.dataset_dir = paths[\"chexpert\"]\r\n",
        "        elif args.dataset_name == \"mimic-chexpert\":\r\n",
        "            args.dataset_dir = [paths[\"chexpert\"], paths[\"mimic\"]]\r\n",
        "        else:\r\n",
        "            raise ValueError(\"Unrecognized path config.\")\r\n",
        "\r\n",
        "    if args.dataset_name in (\"chexpert\", \"mimic\", \"mimic-chexpert\"):\r\n",
        "        args.val_pathology_list = [\r\n",
        "            \"Atelectasis\",\r\n",
        "            \"Cardiomegaly\",\r\n",
        "            \"Consolidation\",\r\n",
        "            \"Edema\",\r\n",
        "            \"Pleural Effusion\",\r\n",
        "        ]\r\n",
        "    elif args.dataset_name == \"nih\":\r\n",
        "        args.val_pathology_list = [\r\n",
        "            \"Atelectasis\",\r\n",
        "            \"Cardiomegaly\",\r\n",
        "            \"Consolidation\",\r\n",
        "            \"Edema\",\r\n",
        "            \"Effusion\",\r\n",
        "        ]\r\n",
        "    else:\r\n",
        "        raise ValueError(\"Unrecognized dataset.\")\r\n",
        "\r\n",
        "    # ------------\r\n",
        "    # checkpoints\r\n",
        "    # ------------\r\n",
        "    checkpoint_dir = Path(args.default_root_dir) / \"checkpoints\"\r\n",
        "    if not checkpoint_dir.exists():\r\n",
        "        checkpoint_dir.mkdir(parents=True)\r\n",
        "    elif args.resume_from_checkpoint is None:\r\n",
        "        ckpt_list = sorted(checkpoint_dir.glob(\"*.ckpt\"), key=os.path.getmtime)\r\n",
        "        if ckpt_list:\r\n",
        "            args.resume_from_checkpoint = str(ckpt_list[-1])\r\n",
        "\r\n",
        "    args.callbacks.append(\r\n",
        "        pl.callbacks.ModelCheckpoint(dirpath=checkpoint_dir, verbose=True)\r\n",
        "    )\r\n",
        "\r\n",
        "    return args\r\n",
        "\r\n",
        "def fetch_pos_weights(dataset_name, csv, label_list, uncertain_label, nan_label):\r\n",
        "    if dataset_name == \"nih\":\r\n",
        "        pos = [(csv[\"Finding Labels\"].str.contains(lab)).sum() for lab in label_list]\r\n",
        "        neg = [(~csv[\"Finding Labels\"].str.contains(lab)).sum() for lab in label_list]\r\n",
        "        pos_weights = torch.tensor((neg / np.maximum(pos, 1)).astype(np.float))\r\n",
        "    else:\r\n",
        "        pos = (csv[label_list] == 1).sum()\r\n",
        "        neg = (csv[label_list] == 0).sum()\r\n",
        "\r\n",
        "        if uncertain_label == 1:\r\n",
        "            pos = pos + (csv[label_list] == -1).sum()\r\n",
        "        elif uncertain_label == -1:\r\n",
        "            neg = neg + (csv[label_list] == -1).sum()\r\n",
        "\r\n",
        "        if nan_label == 1:\r\n",
        "            pos = pos + (csv[label_list].isna()).sum()\r\n",
        "        elif nan_label == -1:\r\n",
        "            neg = neg + (csv[label_list].isna()).sum()\r\n",
        "\r\n",
        "        pos_weights = torch.tensor((neg / np.maximum(pos, 1)).values.astype(np.float))\r\n",
        "\r\n",
        "    return pos_weights"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdFLdQbg36VJ"
      },
      "source": [
        "#args = build_args()\r\n",
        "im_size = 224\r\n",
        "dataset_name = \"mimic\"\r\n",
        "uncertain_label = np.nan\r\n",
        "nan_label = np.nan\r\n",
        "pretrained_file = \"mimic-chexpert_lr_0.01_bs_128_fd_128_qs_65536.pt\"\r\n",
        "batch_size = 1\r\n",
        "num_workers = 4"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZCe7nMoyks6"
      },
      "source": [
        "train_transform_list = [\r\n",
        "        transforms.Resize(im_size),\r\n",
        "        transforms.CenterCrop(im_size),\r\n",
        "        transforms.RandomHorizontalFlip(),\r\n",
        "        transforms.RandomVerticalFlip(),\r\n",
        "        transforms.ToTensor(),\r\n",
        "        HistogramNormalize(),\r\n",
        "        TensorToRGB(),\r\n",
        "        RemapLabel(-1, uncertain_label),\r\n",
        "        NanToInt(nan_label),\r\n",
        "    ]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KV2wRLYl0Eqc"
      },
      "source": [
        "val_transform_list = [\r\n",
        "        transforms.Resize(im_size),\r\n",
        "        transforms.CenterCrop(im_size),\r\n",
        "        transforms.ToTensor(),\r\n",
        "        HistogramNormalize(),\r\n",
        "        TensorToRGB(),\r\n",
        "        RemapLabel(-1, uncertain_label),\r\n",
        "    ]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5ma-aTC8JP1"
      },
      "source": [
        "with open(\"data.yaml\", \"r\") as f:\r\n",
        "  paths = yaml.load(f, Loader=yaml.SafeLoader)[\"paths\"]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoyoYpAp8S7q"
      },
      "source": [
        "if dataset_name == \"nih\":\r\n",
        "  dataset_dir = paths[\"nih\"]\r\n",
        "if dataset_name == \"mimic\":\r\n",
        "  dataset_dir = paths[\"mimic\"]\r\n",
        "elif dataset_name == \"chexpert\":\r\n",
        "  dataset_dir = paths[\"chexpert\"]\r\n",
        "elif dataset_name == \"mimic-chexpert\":\r\n",
        "  dataset_dir = [paths[\"chexpert\"], paths[\"mimic\"]]\r\n",
        "else:\r\n",
        "  raise ValueError(\"Unrecognized path config.\")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jh8Hcwvy8l6d"
      },
      "source": [
        "if dataset_name in (\"chexpert\", \"mimic\", \"mimic-chexpert\"):\r\n",
        "  val_pathology_list = [\r\n",
        "            \"Atelectasis\",\r\n",
        "            \"Cardiomegaly\",\r\n",
        "            \"Consolidation\",\r\n",
        "            \"Edema\",\r\n",
        "            \"Pleural Effusion\",\r\n",
        "        ]\r\n",
        "elif dataset_name == \"nih\":\r\n",
        "       val_pathology_list = [\r\n",
        "            \"Atelectasis\",\r\n",
        "            \"Cardiomegaly\",\r\n",
        "            \"Consolidation\",\r\n",
        "            \"Edema\",\r\n",
        "            \"Effusion\",\r\n",
        "        ]\r\n",
        "else:\r\n",
        "    raise ValueError(\"Unrecognized dataset.\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BBH5QYl8hrF",
        "outputId": "a8071f17-63bb-450e-b394-6221d4f7d033"
      },
      "source": [
        "dataset_dir, val_pathology_list"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('mimic_data',\n",
              " ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9JScGOOJbjM"
      },
      "source": [
        "\"\"\"\r\n",
        "Copyright (c) Facebook, Inc. and its affiliates.\r\n",
        "\r\n",
        "This source code is licensed under the MIT license found in the\r\n",
        "LICENSE file in the root directory of this source tree.\r\n",
        "\"\"\"\r\n",
        "import os\r\n",
        "from argparse import ArgumentParser\r\n",
        "from typing import Callable, List, Optional, Union\r\n",
        "\r\n",
        "from base_dataset import BaseDataset\r\n",
        "import numpy as np\r\n",
        "import pytorch_lightning as pl\r\n",
        "import torch\r\n",
        "from mimic_cxr import MimicCxrJpgDataset\r\n",
        "\r\n",
        "\r\n",
        "class TwoImageDataset(torch.utils.data.Dataset):\r\n",
        "    \"\"\"\r\n",
        "    Wrapper for returning two augmentations of the same image.\r\n",
        "\r\n",
        "    Args:\r\n",
        "        dataset: Pre-initialized data set to return multiple samples from.\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    def __init__(self, dataset: BaseDataset):\r\n",
        "        assert isinstance(dataset, BaseDataset)\r\n",
        "        self.dataset = dataset\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.dataset)\r\n",
        "\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        # randomness handled via the transform objects\r\n",
        "        # this requires the transforms to sample randomness from the process\r\n",
        "        # generator\r\n",
        "        item0 = self.dataset[idx]\r\n",
        "        item1 = self.dataset[idx]\r\n",
        "\r\n",
        "        sample = {\r\n",
        "            \"image0\": item0[\"image\"],\r\n",
        "            \"image1\": item1[\"image\"],\r\n",
        "            \"label\": item0[\"labels\"],\r\n",
        "        }\r\n",
        "\r\n",
        "        return sample\r\n",
        "\r\n",
        "\r\n",
        "def fetch_dataset(\r\n",
        "    dataset_name: str,\r\n",
        "    dataset_dir: Union[List[Union[str, os.PathLike]], Union[str, os.PathLike]],\r\n",
        "    split: str,\r\n",
        "    transform: Optional[Callable],\r\n",
        "    two_image: bool = False,\r\n",
        "    label_list=\"all\",\r\n",
        "):\r\n",
        "    \"\"\"Dataset fetcher for config handling.\"\"\"\r\n",
        "\r\n",
        "    assert split in (\"train\", \"val\", \"test\")\r\n",
        "    dataset: Union[BaseDataset, TwoImageDataset]\r\n",
        "\r\n",
        "    # determine the dataset\r\n",
        "    if dataset_name == \"nih\":\r\n",
        "        assert not isinstance(dataset_dir, list)\r\n",
        "        dataset = NIHChestDataset(\r\n",
        "            directory=dataset_dir,\r\n",
        "            split=split,\r\n",
        "            transform=transform,\r\n",
        "            label_list=label_list,\r\n",
        "            resplit=True,\r\n",
        "        )\r\n",
        "    if dataset_name == \"mimic\":\r\n",
        "        assert not isinstance(dataset_dir, list)\r\n",
        "        print(\"label_list from fetch_dataset: \", label_list)\r\n",
        "        dataset = MimicCxrJpgDataset(\r\n",
        "            directory=dataset_dir,\r\n",
        "            split=split,\r\n",
        "            transform=transform,\r\n",
        "            label_list=label_list,\r\n",
        "        )\r\n",
        "    elif dataset_name == \"chexpert\":\r\n",
        "        assert not isinstance(dataset_dir, list)\r\n",
        "        dataset = CheXpertDataset(\r\n",
        "            directory=dataset_dir,\r\n",
        "            split=split,\r\n",
        "            transform=transform,\r\n",
        "            label_list=label_list,\r\n",
        "        )\r\n",
        "    elif dataset_name == \"mimic-chexpert\":\r\n",
        "        assert isinstance(dataset_dir, list)\r\n",
        "        dataset = CombinedXrayDataset(\r\n",
        "            dataset_list=[\"chexpert_v1\", \"mimic-cxr\"],\r\n",
        "            directory_list=dataset_dir,\r\n",
        "            transform_list=[transform, transform],\r\n",
        "            label_list=[label_list, label_list],\r\n",
        "            split_list=[split, split],\r\n",
        "        )\r\n",
        "    else:\r\n",
        "        raise ValueError(f\"dataset {dataset_name} not recognized\")\r\n",
        "\r\n",
        "    if two_image is True:\r\n",
        "        dataset = TwoImageDataset(dataset)\r\n",
        "\r\n",
        "    return dataset\r\n",
        "\r\n",
        "\r\n",
        "def worker_init_fn(worker_id):\r\n",
        "    \"\"\"Handle random seeding.\"\"\"\r\n",
        "    worker_info = torch.utils.data.get_worker_info()\r\n",
        "    seed = worker_info.seed % (2 ** 32 - 1)  # pylint: disable=no-member\r\n",
        "\r\n",
        "    np.random.seed(seed)\r\n",
        "\r\n",
        "\r\n",
        "class XrayDataModule(pl.LightningDataModule):\r\n",
        "    \"\"\"\r\n",
        "    X-ray data module for training models with PyTorch Lightning.\r\n",
        "\r\n",
        "    Args:\r\n",
        "        dataset_name: Name of the dataset.\r\n",
        "        dataset_dir: Location of the data.\r\n",
        "        label_list: Labels to load for training.\r\n",
        "        batch_size: Training batch size.\r\n",
        "        num_workers: Number of workers for dataloaders.\r\n",
        "        use_two_images: Whether to return two augmentations of same image from\r\n",
        "            dataset (for MoCo pretraining).\r\n",
        "        train_transform: Transform for training loop.\r\n",
        "        val_transform: Transform for validation loop.\r\n",
        "        test_transform: Transform for test loop.\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    def __init__(\r\n",
        "        self,\r\n",
        "        dataset_name: str,\r\n",
        "        dataset_dir: Union[List[Union[str, os.PathLike]], Union[str, os.PathLike]],\r\n",
        "        label_list: Union[str, List[str]] = \"all\",\r\n",
        "        batch_size: int = 1,\r\n",
        "        num_workers: int = 4,\r\n",
        "        use_two_images: bool = False,\r\n",
        "        train_transform: Optional[Callable] = None,\r\n",
        "        val_transform: Optional[Callable] = None,\r\n",
        "        test_transform: Optional[Callable] = None,\r\n",
        "    ):\r\n",
        "        super().__init__()\r\n",
        "        print(\"label_list from XrayDataModule: \", label_list)\r\n",
        "        self.dataset_name = dataset_name\r\n",
        "        self.dataset_dir = dataset_dir\r\n",
        "        self.batch_size = batch_size\r\n",
        "        self.num_workers = num_workers\r\n",
        "\r\n",
        "        self.train_dataset = fetch_dataset(\r\n",
        "            self.dataset_name,\r\n",
        "            self.dataset_dir,\r\n",
        "            \"train\",\r\n",
        "            train_transform,\r\n",
        "            label_list=label_list,\r\n",
        "            two_image=use_two_images,\r\n",
        "        )\r\n",
        "        self.val_dataset = fetch_dataset(\r\n",
        "            self.dataset_name,\r\n",
        "            self.dataset_dir,\r\n",
        "            \"val\",\r\n",
        "            val_transform,\r\n",
        "            label_list=label_list,\r\n",
        "            two_image=use_two_images,\r\n",
        "        )\r\n",
        "        self.test_dataset = fetch_dataset(\r\n",
        "            self.dataset_name,\r\n",
        "            self.dataset_dir,\r\n",
        "            \"test\",\r\n",
        "            test_transform,\r\n",
        "            label_list=label_list,\r\n",
        "            two_image=use_two_images,\r\n",
        "        )\r\n",
        "\r\n",
        "        if isinstance(self.train_dataset, TwoImageDataset):\r\n",
        "            self.label_list = None\r\n",
        "        else:\r\n",
        "            self.label_list = self.train_dataset.label_list\r\n",
        "\r\n",
        "    def __dataloader(self, split: str) -> torch.utils.data.DataLoader:\r\n",
        "        assert split in (\"train\", \"val\", \"test\")\r\n",
        "        shuffle = False\r\n",
        "        if split == \"train\":\r\n",
        "            dataset = self.train_dataset\r\n",
        "            shuffle = True\r\n",
        "        elif split == \"val\":\r\n",
        "            dataset = self.val_dataset\r\n",
        "        else:\r\n",
        "            dataset = self.test_dataset\r\n",
        "\r\n",
        "        loader = torch.utils.data.DataLoader(\r\n",
        "            dataset=dataset,\r\n",
        "            batch_size=self.batch_size,\r\n",
        "            num_workers=self.num_workers,\r\n",
        "            drop_last=True,\r\n",
        "            shuffle=shuffle,\r\n",
        "            worker_init_fn=worker_init_fn,\r\n",
        "        )\r\n",
        "\r\n",
        "        return loader\r\n",
        "\r\n",
        "    def train_dataloader(self):\r\n",
        "        return self.__dataloader(split=\"train\")\r\n",
        "\r\n",
        "    def val_dataloader(self):\r\n",
        "        return self.__dataloader(split=\"val\")\r\n",
        "\r\n",
        "    def test_dataloader(self):\r\n",
        "        return self.__dataloader(split=\"test\")\r\n",
        "\r\n",
        "    @staticmethod\r\n",
        "    def add_model_specific_args(parent_parser):\r\n",
        "        parser = ArgumentParser(parents=[parent_parser], add_help=False)\r\n",
        "\r\n",
        "        parser.add_argument(\"--dataset_name\", default=\"mimic\", type=str)\r\n",
        "        parser.add_argument(\"--dataset_dir\", default=None, type=str)\r\n",
        "        parser.add_argument(\"--batch_size\", default=64, type=int)\r\n",
        "        parser.add_argument(\"--num_workers\", default=4, type=int)\r\n",
        "\r\n",
        "        return parser"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJbZya9I0uwp",
        "outputId": "dc811143-a30a-42e8-a359-135404554832"
      },
      "source": [
        "Compose(val_transform_list)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XRayTransform: Compose"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xl16Dqnz2j2Z"
      },
      "source": [
        "#import pandas as pd\r\n",
        "#directory = \"mimic_data\"\r\n",
        "#split_csv_path = directory+ \"/\"+ \"2.0.0\"+ \"/\"+ \"mimic-cxr-2.0.0-split.csv.gz\"\r\n",
        "#pd.read_csv(split_csv_path)[\"split\"].str.contains(\"train\")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvMBAK7G3V6O",
        "outputId": "6b2f506c-c717-4987-d026-b1f7e4b50ef5"
      },
      "source": [
        "data_module = XrayDataModule(\r\n",
        "        dataset_name=dataset_name,\r\n",
        "        dataset_dir=dataset_dir,\r\n",
        "        batch_size=batch_size,\r\n",
        "        num_workers=num_workers,\r\n",
        "        train_transform=Compose(train_transform_list),\r\n",
        "        val_transform=Compose(val_transform_list),\r\n",
        "        test_transform=Compose(val_transform_list),\r\n",
        "    )"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label_list from XrayDataModule:  all\n",
            "label_list from fetch_dataset:  all\n",
            "label_list from MimicCxrJpgDataset:  all\n",
            "label_list from fetch_dataset:  all\n",
            "label_list from MimicCxrJpgDataset:  all\n",
            "label_list from fetch_dataset:  all\n",
            "label_list from MimicCxrJpgDataset:  all\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2aDX4L0JUoL",
        "outputId": "de6dda1c-378d-462a-e8f6-df184d478f26"
      },
      "source": [
        "data_module.train_dataset"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MimicCxrJpgDataset num_samples=7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3-O-ZKFC-Iz"
      },
      "source": [
        "assert not isinstance(dataset_dir, list)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWOg5MZQDljy"
      },
      "source": [
        "from typing import Callable, List, Optional, Union"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "by3PgGdWDqF9"
      },
      "source": [
        "transform = Optional[Callable]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_9XCSPj9PIb"
      },
      "source": [
        "# ------------\r\n",
        "# model\r\n",
        "# ------------"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UTa7Hki9k7R",
        "outputId": "7c2e3ded-bb85-4dba-c3be-5e98b35272df"
      },
      "source": [
        "fetch_pos_weights(\r\n",
        "    dataset_name=dataset_name,\r\n",
        "    csv=data_module.train_dataset.csv,\r\n",
        "    label_list=data_module.label_list,\r\n",
        "    uncertain_label=uncertain_label,\r\n",
        "    nan_label=nan_label,\r\n",
        ")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIjCN_6C3Xng"
      },
      "source": [
        "pos_weights = fetch_pos_weights(\r\n",
        "    dataset_name=dataset_name,\r\n",
        "    csv=data_module.train_dataset.csv,\r\n",
        "    label_list=data_module.label_list,\r\n",
        "    uncertain_label=uncertain_label,\r\n",
        "    nan_label=nan_label,\r\n",
        ")"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHfunD1NKFZ-"
      },
      "source": [
        "arch = \"densenet121\"\r\n",
        "max_epochs = 1\r\n",
        "learning_rate = 1e-2"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiUZbxVr9XUi",
        "outputId": "016522df-647d-4b7c-a543-bffd01b9254f"
      },
      "source": [
        "model = SipModule(\r\n",
        "      arch=arch,\r\n",
        "      num_classes=len(data_module.label_list),\r\n",
        "      pretrained_file=pretrained_file,\r\n",
        "      label_list=data_module.label_list,\r\n",
        "      val_pathology_list=val_pathology_list,\r\n",
        "      learning_rate=learning_rate,\r\n",
        "      pos_weights=pos_weights,\r\n",
        "      epochs=max_epochs,\r\n",
        "  )"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmK0mprPKgkr",
        "outputId": "8cbaf522-f822-4b1c-83c9-164e654cfa32"
      },
      "source": [
        "pl.Trainer"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pytorch_lightning.trainer.trainer.Trainer"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axqjrgwBLDKm",
        "outputId": "1f4ac836-99d1-40f0-8ce2-0e1cc2e83662"
      },
      "source": [
        "trainer = pl.Trainer()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU available: True, used: False\n",
            "TPU available: None, using: 0 TPU cores\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: GPU available but not used. Set the --gpus flag when calling the script.\n",
            "  warnings.warn(*args, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658,
          "referenced_widgets": [
            "45bc699e94c24cc5b66302699d5e11d1",
            "7b11e708a669457780bb2daf6f0dac0d",
            "721f66da6423425082b0415eb825652b",
            "572d195881844f8fa164f2a283b21fa8",
            "890ec187a75f4ee6b461063e3372fc54",
            "c77cc07e902c4818aa08544f3fb34554",
            "a0125e1269264dfebeabc146010b8f0e",
            "90db964d2ba34afa8b1c480feee39f6f"
          ]
        },
        "id": "otB6q6M0LIK9",
        "outputId": "19a035bb-e347-4f84-ff9b-363140a35b2f"
      },
      "source": [
        "trainer.fit(model, datamodule=data_module)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  | Name      | Type       | Params\n",
            "-----------------------------------------\n",
            "0 | model     | DenseNet   | 7.0 M \n",
            "1 | train_acc | ModuleList | 0     \n",
            "2 | val_acc   | ModuleList | 0     \n",
            "-----------------------------------------\n",
            "7.0 M     Trainable params\n",
            "0         Non-trainable params\n",
            "7.0 M     Total params\n",
            "27.873    Total estimated model params size (MB)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "45bc699e94c24cc5b66302699d5e11d1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "image=  <PIL.Image.Image image mode=F size=2230x2712 at 0x7FD81775B690>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:92: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
            "  img = torch.from_numpy(np.array(pic, np.float32, copy=False))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "path: Atelectasis, len: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-fd0885ca48c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0;31m# dispath `start_training` or `start_testing` or `start_predicting`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;31m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mdispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_or_test_or_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_testing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;31m# double dispatch to initiate the training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_testing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    612\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_bar_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m         \u001b[0;31m# set stage for logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_sanity_check\u001b[0;34m(self, ref_model)\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;31m# run eval step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_sanity_val_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0;31m# allow no returns from eval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_evaluation\u001b[0;34m(self, max_batches, on_epoch)\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0;31m# lightning module method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m         \u001b[0mdeprecated_eval_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0;31m# hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/evaluation_loop.py\u001b[0m in \u001b[0;36mevaluation_epoch_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;31m# call the model epoch end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mdeprecated_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__run_eval_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_dataloaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;31m# enable returning anything\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/evaluation_loop.py\u001b[0m in \u001b[0;36m__run_eval_epoch_end\u001b[0;34m(self, num_dataloaders)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_overridden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'validation_epoch_end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_fx_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'validation_epoch_end'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m                 \u001b[0meval_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m                 \u001b[0muser_reduced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/sip_finetune.py\u001b[0m in \u001b[0;36mvalidation_epoch_end\u001b[0;34m(self, outputs)\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"path: {path}, len: {len(logits)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_acc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0mauc_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauroc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/metrics/metric.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;31m# add current step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/metrics/metric.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_computed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/metrics/classification/accuracy.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, preds, target)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         correct, total = _accuracy_update(\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset_accuracy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubset_accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         )\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/metrics/functional/accuracy.py\u001b[0m in \u001b[0;36m_accuracy_update\u001b[0;34m(preds, target, threshold, top_k, subset_accuracy)\u001b[0m\n\u001b[1;32m     23\u001b[0m ) -> Tuple[torch.Tensor, torch.Tensor]:\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_input_format_classification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mDataType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMULTILABEL\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/metrics/classification/helpers.py\u001b[0m in \u001b[0;36m_input_format_classification\u001b[0;34m(preds, target, threshold, top_k, num_classes, is_multiclass)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0mis_multiclass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_multiclass\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m     )\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/metrics/classification/helpers.py\u001b[0m in \u001b[0;36m_check_classification_inputs\u001b[0;34m(preds, target, threshold, num_classes, is_multiclass, top_k)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;31m# Baisc validation (that does not need case/type information)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m     \u001b[0m_basic_input_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_multiclass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;31m# Check that shape/types fall into one of the cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/metrics/classification/helpers.py\u001b[0m in \u001b[0;36m_basic_input_validation\u001b[0;34m(preds, target, threshold, is_multiclass)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The `target` has to be an integer tensor.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The `target` has to be a non-negative tensor.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The `target` has to be an integer tensor."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIK791TMNsSC",
        "outputId": "3678ee8a-17d4-483b-b02c-d06400b82f0e"
      },
      "source": [
        "data_module.train_dataset.labels"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['No Finding',\n",
              " 'Enlarged Cardiomediastinum',\n",
              " 'Cardiomegaly',\n",
              " 'Lung Opacity',\n",
              " 'Lung Lesion',\n",
              " 'Edema',\n",
              " 'Consolidation',\n",
              " 'Pneumonia',\n",
              " 'Atelectasis',\n",
              " 'Pneumothorax',\n",
              " 'Pleural Effusion',\n",
              " 'Pleural Other',\n",
              " 'Fracture',\n",
              " 'Support Devices']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDCAUN1cPW5I"
      },
      "source": [
        "data_modu"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}