{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FB_Covid.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPtTWVWiJQR3CqyCytV0Edp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanmayg/LS/blob/master/FB_Covid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeNU4Ode7l7k",
        "outputId": "4f3ee117-c770-41df-f44f-eb63aeb18731"
      },
      "source": [
        "!pip install pytorch_lightning"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch_lightning\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/38/38/f010c6de967dd9e3c765a252d0551aff7194bab90b681407c5d702ca22df/pytorch_lightning-1.2.0-py3-none-any.whl (813kB)\n",
            "\u001b[K     |████████████████████████████████| 819kB 995kB/s \n",
            "\u001b[?25hCollecting fsspec[http]>=0.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/0d/a6bfee0ddf47b254286b9bd574e6f50978c69897647ae15b14230711806e/fsspec-0.8.7-py3-none-any.whl (103kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 3.2MB/s \n",
            "\u001b[?25hCollecting PyYAML!=5.4.*,>=5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 2.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2.4.1)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.41.1)\n",
            "Collecting future>=0.17.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 2.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from fsspec[http]>=0.8.1->pytorch_lightning) (3.4.0)\n",
            "Collecting aiohttp; extra == \"http\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/a2/4eea05bac4b04be79d23159c25ddd13b5fd48c1f844fb3a6427cfadbfffd/aiohttp-3.7.3-cp37-cp37m-manylinux2014_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 3.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests; extra == \"http\" in /usr/local/lib/python3.7/dist-packages (from fsspec[http]>=0.8.1->pytorch_lightning) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.8.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.12.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.4.2)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.32.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.15.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.27.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.36.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (53.0.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.10.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->pytorch_lightning) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->pytorch_lightning) (0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->fsspec[http]>=0.8.1->pytorch_lightning) (3.4.0)\n",
            "Collecting async-timeout<4.0,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: chardet<4.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch_lightning) (3.0.4)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/62/046834c5fc998c88ab2ef722f5d42122230a632212c8afa76418324f53ff/yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 4.4MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a6/4123b8165acbe773d1a8dc8e3f0d1edea16d29f7de018eda769abb56bd30/multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 4.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch_lightning) (20.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests; extra == \"http\"->fsspec[http]>=0.8.1->pytorch_lightning) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests; extra == \"http\"->fsspec[http]>=0.8.1->pytorch_lightning) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests; extra == \"http\"->fsspec[http]>=0.8.1->pytorch_lightning) (1.24.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.7.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.2.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.4.8)\n",
            "Building wheels for collected packages: PyYAML, future\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp37-cp37m-linux_x86_64.whl size=44620 sha256=e114d4d198738b3c58cd1164d8d27ab0b0f64b908d473a89bb2938bf55b6bab8\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-cp37-none-any.whl size=491058 sha256=95f3b3a4ea71d729af0ca8f536bf78d7f8ada74b0fee73427a486d8e9718815d\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "Successfully built PyYAML future\n",
            "Installing collected packages: async-timeout, multidict, yarl, aiohttp, fsspec, PyYAML, future, pytorch-lightning\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "Successfully installed PyYAML-5.3.1 aiohttp-3.7.3 async-timeout-3.0.1 fsspec-0.8.7 future-0.18.2 multidict-5.1.0 pytorch-lightning-1.2.0 yarl-1.6.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkJV1bUsOiuT"
      },
      "source": [
        "import logging\r\n",
        "import os\r\n",
        "from argparse import ArgumentParser\r\n",
        "from pathlib import Path\r\n",
        "from warnings import warn\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import pytorch_lightning as pl\r\n",
        "import torch\r\n",
        "import yaml\r\n",
        "import argparse\r\n",
        "\r\n",
        "argparser = argparse.ArgumentParser()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Omthm1q7rf0z",
        "outputId": "07420d25-8c5f-40a8-bb8b-cdee10a18639"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08Yh_wU8Pnrp"
      },
      "source": [
        "from transforms import (\r\n",
        "    Compose,\r\n",
        "    HistogramNormalize,\r\n",
        "    NanToInt,\r\n",
        "    RemapLabel,\r\n",
        "    TensorToRGB,\r\n",
        ")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zm1esry_P0WQ"
      },
      "source": [
        "from xray_datamodule import XrayDataModule"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6Lg0rrkP52x"
      },
      "source": [
        "from torchvision import transforms\r\n",
        "from sip_finetune import SipModule"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZY0iJaISFgY"
      },
      "source": [
        "#!python train_sip.py --pretrained_file mimic-chexpert_lr_0.01_bs_128_fd_128_qs_65536.pt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_HfjWKGER58"
      },
      "source": [
        "argparser.add_argument(\"--pretrained_file\", help=\"Pretrained File\", default=\"mimic-chexpert_lr_0.01_bs_128_fd_128_qs_65536.pt\")\r\n",
        "args = argparser.parse_args([\"--pretrained_file\", \"mimic-chexpert_lr_0.01_bs_128_fd_128_qs_65536.pt\"])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IU2p7YX7AjO6",
        "outputId": "c30e4da4-a562-4b03-f220-d4dcf19d5c72"
      },
      "source": [
        "args"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Namespace(pretrained_file='mimic-chexpert_lr_0.01_bs_128_fd_128_qs_65536.pt')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gr4ffHStjwJ"
      },
      "source": [
        "def build_args(arg_defaults=None):\r\n",
        "    pl.seed_everything(1234)\r\n",
        "    data_config = Path.cwd() / \"data.yaml\"\r\n",
        "    tmp = arg_defaults\r\n",
        "    arg_defaults = {\r\n",
        "        \"accelerator\": \"ddp\",\r\n",
        "        \"batch_size\": 32,\r\n",
        "        \"max_epochs\": 5,\r\n",
        "        \"gpus\": 1,\r\n",
        "        \"num_workers\": 10,\r\n",
        "        \"callbacks\": [],\r\n",
        "    }\r\n",
        "    if tmp is not None:\r\n",
        "        arg_defaults.update(tmp)\r\n",
        "\r\n",
        "    # ------------\r\n",
        "    # args\r\n",
        "    # ------------\r\n",
        "    parser = ArgumentParser()\r\n",
        "    parser.add_argument(\"--im_size\", default=224, type=int)\r\n",
        "    parser.add_argument(\"--uncertain_label\", default=np.nan, type=float)\r\n",
        "    parser.add_argument(\"--nan_label\", default=np.nan, type=float)\r\n",
        "    parser = pl.Trainer.add_argparse_args(parser)\r\n",
        "    parser = XrayDataModule.add_model_specific_args(parser)\r\n",
        "    parser = SipModule.add_model_specific_args(parser)\r\n",
        "    parser.set_defaults(**arg_defaults)\r\n",
        "    args = parser.parse_args()\r\n",
        "\r\n",
        "    if args.default_root_dir is None:\r\n",
        "        args.default_root_dir = Path.cwd()\r\n",
        "\r\n",
        "    if args.pretrained_file is None:\r\n",
        "        warn(\"Pretrained file not specified, training from scratch.\")\r\n",
        "    else:\r\n",
        "        logging.info(f\"Loading pretrained file from {args.pretrained_file}\")\r\n",
        "\r\n",
        "    if args.dataset_dir is None:\r\n",
        "        with open(data_config, \"r\") as f:\r\n",
        "            paths = yaml.load(f, Loader=yaml.SafeLoader)[\"paths\"]\r\n",
        "\r\n",
        "        if args.dataset_name == \"nih\":\r\n",
        "            args.dataset_dir = paths[\"nih\"]\r\n",
        "        if args.dataset_name == \"mimic\":\r\n",
        "            args.dataset_dir = paths[\"mimic\"]\r\n",
        "        elif args.dataset_name == \"chexpert\":\r\n",
        "            args.dataset_dir = paths[\"chexpert\"]\r\n",
        "        elif args.dataset_name == \"mimic-chexpert\":\r\n",
        "            args.dataset_dir = [paths[\"chexpert\"], paths[\"mimic\"]]\r\n",
        "        else:\r\n",
        "            raise ValueError(\"Unrecognized path config.\")\r\n",
        "\r\n",
        "    if args.dataset_name in (\"chexpert\", \"mimic\", \"mimic-chexpert\"):\r\n",
        "        args.val_pathology_list = [\r\n",
        "            \"Atelectasis\",\r\n",
        "            \"Cardiomegaly\",\r\n",
        "            \"Consolidation\",\r\n",
        "            \"Edema\",\r\n",
        "            \"Pleural Effusion\",\r\n",
        "        ]\r\n",
        "    elif args.dataset_name == \"nih\":\r\n",
        "        args.val_pathology_list = [\r\n",
        "            \"Atelectasis\",\r\n",
        "            \"Cardiomegaly\",\r\n",
        "            \"Consolidation\",\r\n",
        "            \"Edema\",\r\n",
        "            \"Effusion\",\r\n",
        "        ]\r\n",
        "    else:\r\n",
        "        raise ValueError(\"Unrecognized dataset.\")\r\n",
        "\r\n",
        "    # ------------\r\n",
        "    # checkpoints\r\n",
        "    # ------------\r\n",
        "    checkpoint_dir = Path(args.default_root_dir) / \"checkpoints\"\r\n",
        "    if not checkpoint_dir.exists():\r\n",
        "        checkpoint_dir.mkdir(parents=True)\r\n",
        "    elif args.resume_from_checkpoint is None:\r\n",
        "        ckpt_list = sorted(checkpoint_dir.glob(\"*.ckpt\"), key=os.path.getmtime)\r\n",
        "        if ckpt_list:\r\n",
        "            args.resume_from_checkpoint = str(ckpt_list[-1])\r\n",
        "\r\n",
        "    args.callbacks.append(\r\n",
        "        pl.callbacks.ModelCheckpoint(dirpath=checkpoint_dir, verbose=True)\r\n",
        "    )\r\n",
        "\r\n",
        "    return args\r\n",
        "\r\n",
        "def fetch_pos_weights(dataset_name, csv, label_list, uncertain_label, nan_label):\r\n",
        "    if dataset_name == \"nih\":\r\n",
        "        pos = [(csv[\"Finding Labels\"].str.contains(lab)).sum() for lab in label_list]\r\n",
        "        neg = [(~csv[\"Finding Labels\"].str.contains(lab)).sum() for lab in label_list]\r\n",
        "        pos_weights = torch.tensor((neg / np.maximum(pos, 1)).astype(np.float))\r\n",
        "    else:\r\n",
        "        pos = (csv[label_list] == 1).sum()\r\n",
        "        neg = (csv[label_list] == 0).sum()\r\n",
        "\r\n",
        "        if uncertain_label == 1:\r\n",
        "            pos = pos + (csv[label_list] == -1).sum()\r\n",
        "        elif uncertain_label == -1:\r\n",
        "            neg = neg + (csv[label_list] == -1).sum()\r\n",
        "\r\n",
        "        if nan_label == 1:\r\n",
        "            pos = pos + (csv[label_list].isna()).sum()\r\n",
        "        elif nan_label == -1:\r\n",
        "            neg = neg + (csv[label_list].isna()).sum()\r\n",
        "\r\n",
        "        pos_weights = torch.tensor((neg / np.maximum(pos, 1)).values.astype(np.float))\r\n",
        "\r\n",
        "    return pos_weights"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZCe7nMoyks6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}